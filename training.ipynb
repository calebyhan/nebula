{
 "cells": [
  {
   "cell_type": "code",
   "id": "01165675",
   "metadata": {},
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "type = \"apple\"\n",
    "\n",
    "if type == \"apple\":\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "    print(\"Available devices:\")\n",
    "    for device in tf.config.list_physical_devices():\n",
    "        print(device)\n",
    "\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(f\"✅ GPU detected: {gpus}\")\n",
    "    else:\n",
    "        print(\"⚠️ No GPU found — check if tensorflow-metal is installed and you're using Apple Silicon.\")\n",
    "\n",
    "else:\n",
    "    os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(\"Available GPUs:\", gpus)\n",
    "\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"Memory growth enabled\")\n",
    "        except RuntimeError as e:\n",
    "            print(\"Could not set memory growth:\", e)"
   ],
   "id": "f383a74ddcbd7963",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "INPUT_DIR = \"data/\"\n",
    "TARGET_SIZE = (512, 512)\n",
    "DATA_PATH = f\"processed/processed_nebula_dataset_{TARGET_SIZE[0]}.npy\"\n",
    "BATCH_SIZE = 32\n",
    "LATENT_DIM = 100\n",
    "IMG_SHAPE = (TARGET_SIZE[0], TARGET_SIZE[1], 3)\n",
    "EPOCHS = 5000\n",
    "N_CRITIC = 5\n",
    "LAMBDA_GP = 10.0\n",
    "SAVE_INTERVAL = 500\n",
    "EPOCH_D = 100"
   ],
   "id": "4232bc706dec391e"
  },
  {
   "cell_type": "code",
   "id": "50af22e6",
   "metadata": {},
   "source": [
    "def get_all_jpg_images(folder_path):\n",
    "    jpg_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".jpg\"):\n",
    "                jpg_paths.append(os.path.join(root, file))\n",
    "    return jpg_paths\n",
    "\n",
    "def center_crop_and_resize(image_path, target_size=TARGET_SIZE):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        w, h = img.size\n",
    "        min_dim = min(w, h)\n",
    "        left = (w - min_dim) // 2\n",
    "        top = (h - min_dim) // 2\n",
    "        img = img.crop((left, top, left + min_dim, top + min_dim))\n",
    "        img = img.resize(target_size, Image.LANCZOS)\n",
    "        img = np.array(img).astype(np.float32) / 127.5 - 1.0\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] Skipping {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_all_images(image_paths):\n",
    "    images = []\n",
    "    for i, path in enumerate(image_paths):\n",
    "        processed = center_crop_and_resize(path)\n",
    "        if processed is not None:\n",
    "            images.append(processed)\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Processed {i+1}/{len(image_paths)} images...\")\n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if os.path.exists(DATA_PATH):\n",
    "        print(f\"{DATA_PATH} already exists.\")\n",
    "    else:\n",
    "        print(\"Collecting .jpg images...\")\n",
    "        image_paths = get_all_jpg_images(INPUT_DIR)\n",
    "        print(f\"Found {len(image_paths)} images.\")\n",
    "\n",
    "        print(\"Preprocessing images...\")\n",
    "        dataset = process_all_images(image_paths)\n",
    "        print(f\"Final dataset shape: {dataset.shape}\")\n",
    "\n",
    "        print(f\"Saving to {DATA_PATH}...\")\n",
    "        np.save(DATA_PATH, dataset)\n",
    "        print(\"Done!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "186c9d1f",
   "metadata": {},
   "source": [
    "data = np.load(DATA_PATH).astype(np.float32)\n",
    "print(\"Data shape:\", data.shape)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(buffer_size=1024).batch(BATCH_SIZE).prefetch(1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "08b4aa87",
   "metadata": {},
   "source": [
    "def build_generator(latent_dim):\n",
    "    if TARGET_SIZE == (64, 64):\n",
    "        model = models.Sequential([\n",
    "            layers.Dense(4 * 4 * 256, input_dim=latent_dim),\n",
    "            layers.Reshape((4, 4, 256)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(128, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(64, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')\n",
    "        ])\n",
    "    elif TARGET_SIZE == (128, 128):\n",
    "        model = models.Sequential([\n",
    "            layers.Dense(4 * 4 * 512, input_dim=latent_dim),\n",
    "            layers.Reshape((4, 4, 512)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(256, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(128, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(64, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(32, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')\n",
    "        ])\n",
    "    elif TARGET_SIZE == (256, 256):\n",
    "        model = models.Sequential([\n",
    "            layers.Dense(4 * 4 * 1024, input_dim=latent_dim),\n",
    "            layers.Reshape((4, 4, 1024)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(512, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(256, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(128, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(64, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(32, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')\n",
    "        ])\n",
    "    elif TARGET_SIZE == (512, 512):\n",
    "        model = models.Sequential([\n",
    "            layers.Dense(4 * 4 * 1024, input_dim=latent_dim),\n",
    "            layers.Reshape((4, 4, 1024)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(512, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(256, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(128, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(64, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(32, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(16, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')\n",
    "        ])\n",
    "    else:\n",
    "        return None\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec348de4",
   "metadata": {},
   "source": [
    "def build_discriminator(img_shape):\n",
    "    if TARGET_SIZE == (64, 64):\n",
    "        model = models.Sequential([\n",
    "            layers.Input(shape=img_shape),\n",
    "\n",
    "            layers.Conv2D(64, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(128, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(256, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1),\n",
    "        ])\n",
    "    elif TARGET_SIZE == (128, 128):\n",
    "        model = models.Sequential([\n",
    "            layers.Input(shape=img_shape),\n",
    "\n",
    "            layers.Conv2D(64, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(128, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(256, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(512, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(512, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1),\n",
    "        ])\n",
    "    elif TARGET_SIZE == (256, 256):\n",
    "        model = models.Sequential([\n",
    "            layers.Input(shape=img_shape),\n",
    "\n",
    "            layers.Conv2D(64, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(128, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(256, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(512, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(512, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(512, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1),\n",
    "        ])\n",
    "    elif TARGET_SIZE == (512, 512):\n",
    "        model = models.Sequential([\n",
    "            layers.Input(shape=img_shape),\n",
    "\n",
    "            layers.Conv2D(64, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(128, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(256, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(512, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(512, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(512, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Conv2D(512, 4, strides=2, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1),\n",
    "        ])\n",
    "    else:\n",
    "        return None\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1eab3198",
   "metadata": {},
   "source": [
    "generator = build_generator(LATENT_DIM)\n",
    "discriminator = build_discriminator(IMG_SHAPE)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5e1b5eb6",
   "metadata": {},
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "def gradient_penalty(discriminator, real_images, fake_images):\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "    epsilon = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    interpolated = epsilon * real_images + (1 - epsilon) * fake_images\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated)\n",
    "        pred = discriminator(interpolated)\n",
    "    grads = tape.gradient(pred, interpolated)\n",
    "    grads_norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]) + 1e-12)\n",
    "    gp = tf.reduce_mean((grads_norm - 1.0) ** 2)\n",
    "    return gp"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3d85df3f",
   "metadata": {},
   "source": [
    "@tf.function\n",
    "def train_discriminator(real_images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake_images = generator(noise, training=True)\n",
    "        real_output = discriminator(real_images, training=True)\n",
    "        fake_output = discriminator(fake_images, training=True)\n",
    "\n",
    "        gp = gradient_penalty(discriminator, real_images, fake_images)\n",
    "        d_loss = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output) + LAMBDA_GP * gp\n",
    "\n",
    "    gradients = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients, discriminator.trainable_variables))\n",
    "    return d_loss, tf.reduce_mean(real_output), tf.reduce_mean(fake_output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df52fc91",
   "metadata": {},
   "source": [
    "@tf.function\n",
    "def train_generator():\n",
    "    noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake_images = generator(noise, training=True)\n",
    "        fake_output = discriminator(fake_images, training=True)\n",
    "        g_loss = -tf.reduce_mean(fake_output)\n",
    "    gradients = tape.gradient(g_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\n",
    "    return g_loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "24f68e04",
   "metadata": {},
   "source": [
    "def save_generated_images(epoch, n=5):\n",
    "    noise = tf.random.normal([n*n, LATENT_DIM])\n",
    "    generated_images = generator(noise, training=False)\n",
    "    generated_images = (generated_images + 1.0) / 2.0\n",
    "\n",
    "    dpi = 100\n",
    "    img_size = IMG_SHAPE[0]\n",
    "    figsize = (n * img_size / dpi, n * img_size / dpi)\n",
    "\n",
    "    fig, axs = plt.subplots(n, n, figsize=figsize, dpi=dpi)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05, left=0.1, right=0.9, top=0.9, bottom=0.1)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            axs[i, j].imshow(generated_images[i*n + j])\n",
    "            axs[i, j].axis('off')\n",
    "\n",
    "    os.makedirs(\"generated\", exist_ok=True)\n",
    "    plt.savefig(f\"{TARGET_SIZE[0]}/nebula_wgan_gp_epoch_{epoch}.png\", dpi=dpi, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c2b26e01",
   "metadata": {},
   "source": [
    "def train(dataset, epochs):\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    real_scores = []\n",
    "    fake_scores = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training epochs\"):\n",
    "        dataset_iter = iter(dataset)\n",
    "    \n",
    "        for _ in range(N_CRITIC):\n",
    "            real_batch = next(dataset_iter)\n",
    "            d_loss, real_score, fake_score = train_discriminator(real_batch)\n",
    "\n",
    "        g_loss = train_generator()\n",
    "\n",
    "        d_losses.append(float(d_loss))\n",
    "        g_losses.append(float(g_loss))\n",
    "        real_scores.append(float(real_score))\n",
    "        fake_scores.append(float(fake_score))\n",
    "\n",
    "        if epoch % EPOCH_D == 0:\n",
    "            print(f\"Epoch {epoch}, D loss: {d_loss:.4f}, real_score: {real_score:.4f}, fake_score: {fake_score:.4f}, G loss: {g_loss:.4f}\")\n",
    "\n",
    "        if epoch % SAVE_INTERVAL == 0:\n",
    "            save_generated_images(epoch)\n",
    "\n",
    "    return d_losses, real_scores, fake_scores, g_losses"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "661c3e38",
   "metadata": {},
   "source": [
    "def plot_training_history(d_losses, g_losses):\n",
    "    epochs = range(len(d_losses))\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, d_losses, label='Discriminator Loss')\n",
    "    plt.plot(epochs, g_losses, label='Generator Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{TARGET_SIZE[0]}/plot_losses\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "456aca60",
   "metadata": {},
   "source": [
    "d_losses, real_scores, fake_scores, g_losses = train(dataset, EPOCHS)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f770620",
   "metadata": {},
   "source": [
    "plot_training_history(d_losses, g_losses)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99c49743",
   "metadata": {},
   "source": [
    "def generate_and_show_images(generator, latent_dim, n=5):\n",
    "    noise = np.random.normal(0, 1, (n * n, latent_dim))\n",
    "    \n",
    "    generated_images = generator.predict(noise)\n",
    "    \n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "    \n",
    "    fig, axs = plt.subplots(n, n, figsize=(n, n))\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05, left=0.1, right=0.9, top=0.9, bottom=0.1)\n",
    "\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            axs[i, j].imshow(generated_images[count])\n",
    "            axs[i, j].axis('off')\n",
    "            count += 1\n",
    "\n",
    "    plt.savefig(f\"{TARGET_SIZE[0]}/generated_images.png\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e86433f7",
   "metadata": {},
   "source": [
    "generate_and_show_images(generator, latent_dim=100, n=5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88d3906e",
   "metadata": {},
   "source": [
    "generator.summary()\n",
    "generator.save(f\"{TARGET_SIZE[0]}/generator.keras\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1984aa29",
   "metadata": {},
   "source": [
    "discriminator.summary()\n",
    "discriminator.save(f\"{TARGET_SIZE[0]}/discriminator.keras\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epochs = list(range(0, EPOCHS, EPOCH_D))\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.plot(epochs, real_scores, label='Real Score', color='green', linestyle='-')\n",
    "plt.plot(epochs, fake_scores, label='Fake Score', color='red', linestyle='-')\n",
    "\n",
    "plt.title(\"Real vs Fake Discriminator Scores\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{TARGET_SIZE[0]}/scores\")\n",
    "plt.show()"
   ],
   "id": "762f2dce9a2a1b50",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
